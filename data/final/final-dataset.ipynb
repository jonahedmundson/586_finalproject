{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c38118dc",
   "metadata": {},
   "source": [
    "# Creating Final Dataset\n",
    "\n",
    "## Relinking photos with Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "325c5f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1510\n",
      "95\n",
      "284\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#read in existing dataframe\n",
    "df = pd.read_csv('../congress2023-04-11.csv', index_col=0)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "#main loop\n",
    "missing = []\n",
    "parray = []\n",
    "#df[\"picArray\"] = np.nan\n",
    "\n",
    "for i, value in enumerate(df['photo']):\n",
    "    cid = (value)[12:23]\n",
    "    \n",
    "    try:\n",
    "        cphoto = cv2.imread('../photos/' + cid + '.jpg')\n",
    "        parray.append(cphoto)\n",
    "        \n",
    "    except:\n",
    "        #print(\"Error on iteration\", i, 'with image id:', cid)\n",
    "        parray.append(None)\n",
    "        missing.append(value)\n",
    "    \n",
    "    #if i == 3:\n",
    "    #    break\n",
    "      \n",
    "#save image array as df column\n",
    "df['picArray'] = parray\n",
    "\n",
    "#removing rows with no party affiliation\n",
    "df = df[df['party'].isin(['R', 'D'])]\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "#dropping rows with no image\n",
    "df = df.dropna(axis=0, subset='picArray')\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "#shuffling order\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "#creating train, validation and test sets --> 80/5/15 rule\n",
    "train = df.iloc[0:1510] #1510\n",
    "valid = df.iloc[1510:1605] #95\n",
    "test = df.iloc[1605:] #283 rows\n",
    "\n",
    "#check\n",
    "print(len(train.index))\n",
    "print(len(valid.index))\n",
    "print(len(test.index))\n",
    "\n",
    "#save it\n",
    "#train is too big, need to split it\n",
    "train_split = np.array_split(train, 2)\n",
    "#saving\n",
    "train_split[0].to_pickle('UScongress_train_1.pkl')\n",
    "train_split[1].to_pickle('UScongress_train_2.pkl')\n",
    "valid.to_pickle('UScongress_validation.pkl')\n",
    "test.to_pickle('UScongress_test.pkl')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#old saving method\n",
    "#split into republicans and democrats\n",
    "#dems = df.loc[df.party == 'D']\n",
    "#repubs = df.loc[df.party == 'R']\n",
    "\n",
    "#split each into 3 to fit with Git's file size limits :(\n",
    "#dems_split = np.array_split(dems, 3)\n",
    "#repubs_split = np.array_split(repubs, 3)\n",
    "\n",
    "#save them\n",
    "#for i in range(3):\n",
    "#    dems_split[i].to_pickle('democrat_faces_' + str(i) + '.pkl')\n",
    "#    repubs_split[i].to_pickle('republican_faces' + str(i) + '.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3949799b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1510\n",
      "95\n",
      "284\n"
     ]
    }
   ],
   "source": [
    "#double check that we can read them in fine\n",
    "\n",
    "import pandas as pd\n",
    "train1 = pd.read_pickle('UScongress_train_1.pkl')\n",
    "train2 = pd.read_pickle('UScongress_train_2.pkl')\n",
    "train = pd.concat([train1, train2])\n",
    "valid = pd.read_pickle('UScongress_validation.pkl')\n",
    "test = pd.read_pickle('UScongress_test.pkl')\n",
    "del(train1, train2)\n",
    "\n",
    "print(len(train.index))\n",
    "print(len(valid.index))\n",
    "print(len(test.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "22266d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "D    1227\n",
       "R    1211\n",
       "Name: party, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #check - read them in\n",
    "# import pandas as pd\n",
    "# dems = []\n",
    "# repubs = []\n",
    "\n",
    "# for i in range(3):\n",
    "#     dems.append(pd.read_pickle('democrat_faces_' + str(i) + '.pkl'))\n",
    "#     repubs.append(pd.read_pickle('republican_faces' + str(i) + '.pkl')) \n",
    "\n",
    "    \n",
    "# dems = pd.concat(dems)\n",
    "# repubs = pd.concat(repubs)\n",
    "# df = pd.concat([dems, repubs])\n",
    "# df = df.reset_index(drop=True)\n",
    "# df['party'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad80bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
